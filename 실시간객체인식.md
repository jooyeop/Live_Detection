### 커스텀데이터를 만들기위해 labelIMG 설치
1. https://github.com/HumanSignal/labelImg - github에서 zip 파일 다운로드 후
2. 터미널에서 pyqt, lxml, pyrcc5 설치(pyrcc5는 관리자권한 필수)
3. python labelimg.py 실행

### 박스 작업
1. classes에 candy만 저장
2. labels 파일에 클래스, 박스의 좌표 확인

### 파이썬을통해 훈련데이터를 위한 yaml 파일 생성
```
data = {
    'train' : 'dataset/train/',
    'val' : 'dataset/valid/',
    'test' : 'dataset/test/',
    'names' : {0 : 'candy'}
}

with open('./candy.yaml', 'w') as f:
    yaml.dump(data, f)
    
with open('./candy.yaml', 'r') as f:
    lines = yaml.safe_load(f)
    print(lines)
```

### 생성된 yaml 파일확인
```
names:
  0: candy
test: dataset/test/
train: dataset/train/
val: dataset/valid/
```

### YOLO모듈을 통해 model 학습
```
from ultralytics import YOLO

model = YOLO('yolov8s.pt')
model.train(data = './candy.yaml', epochs = 20)
```

### 학습된 사진 확인

![image](https://github.com/jooyeop/Live_Detection/assets/97720878/0bee67fe-fb20-4006-91af-75e524082838)

![image](https://github.com/jooyeop/Live_Detection/assets/97720878/85f8b475-e1b4-41a8-b7f8-077ba6e492e6)

![image](https://github.com/jooyeop/Live_Detection/assets/97720878/f57d467e-1ec8-4f68-9d18-e033ce0daf9c)


### 검증사진 확인

![image](https://github.com/jooyeop/Live_Detection/assets/97720878/62e77c50-2609-4d50-8ab1-af6716b0c220)


### 성능확인
Recall-Confidence Curve

![image](https://github.com/jooyeop/Live_Detection/assets/97720878/1816d83d-0b15-4176-bb9c-87a9fcc68f22)

Precision-Recall Curve

![image](https://github.com/jooyeop/Live_Detection/assets/97720878/907d7240-5a00-4bd1-bac1-e949fd5a1d14)

Precision-Confidence Curve

![image](https://github.com/jooyeop/Live_Detection/assets/97720878/a56e260e-7793-4095-8838-bf5e26a66a18)

F1-Confidence Curve

![image](https://github.com/jooyeop/Live_Detection/assets/97720878/80393dbc-eda9-4c2b-81d9-1d638c192f4f)

labels

![image](https://github.com/jooyeop/Live_Detection/assets/97720878/e24756de-fa74-41ca-b772-6249600a167f)

### 저장된 best.pt 파일로 실시간 객체탐지 실시
사진을 통한 테스트
```
import cv2
from ultralytics import YOLO

model = YOLO('best.pt')
results = model('./dataset/test/images/WIN_20230925_13_26_51_Pro.jpg')

plots = results[0].plot()
cv2.imshow('plots', plots)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

![image](https://github.com/jooyeop/Live_Detection/assets/97720878/2db9c9c7-0528-41d4-b971-e21a2100ae63)

캠연결 후 라이브테스트
```
import datetime
import cv2
from ultralytics import YOLO

CONFIDENCE_THRESHOLD = 0.6
GREEN = (0, 255, 0)
WHITE = (255, 255, 255)

classes = open('./dataset/train/classes.txt', 'r')
data = classes.read()
class_list = data.split('\n')
classes.close()

model = YOLO('best.pt')

# 웹캠 연결
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

while True:
    start = datetime.datetime.now()

    ret, frame = cap.read()
    if not ret:
        print('Cam Error')
        break

    detection = model(frame)[0]

    for data in detection.boxes.data.tolist(): # data : [xmin, ymin, xmax, ymax, confidence_score, class_id]
        confidence = float(data[4])
        if confidence < CONFIDENCE_THRESHOLD:
            continue

        xmin, ymin, xmax, ymax = int(data[0]), int(data[1]), int(data[2]), int(data[3])
        label = int(data[5])
        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), GREEN, 2)
        cv2.putText(frame, class_list[label]+' '+str(round(confidence, 2)) + '%', (xmin, ymin), cv2.FONT_ITALIC, 1, WHITE, 2)

    end = datetime.datetime.now()

    total = (end - start).total_seconds()
    print(f'Time to process 1 frame: {total * 1000:.0f} milliseconds')

    fps = f'FPS: {1 / total:.2f}'
    cv2.putText(frame, fps, (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)

    cv2.imshow('frame', frame)

    if cv2.waitKey(1) == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

![image](https://github.com/jooyeop/Live_Detection/assets/97720878/c865a158-56d6-4960-b047-8ed9c284807b)




